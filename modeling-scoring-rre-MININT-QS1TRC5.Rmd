---
title: "Modeling and Scoring with Revolution R Enterprise"
author: "Ali Zaidi"
date: "April 1, 2016"
output:
  ioslides_presentation:
    logo: logo-130833979438186239.png
    smaller: yes
    widescreen: yes
  beamer_presentation: default
  slidy_presentation: default
transition: rotate
---


# Introduction

## URL for Today

Please refer to the following url for today's materials:
[http://tinyurl.com/j7okpak](http://tinyurl.com/j7okpak)

## Session Plan | What to Expect

- We will learn in this tutorial how to train and test
models with Revolution R Enterprise.
- Use your knowledge of data manipulation to create **train** and **test** sets.
- Use the modeling functions in RRE to estimate a model.
- Use the `rxPredict` function to test/score a model.
- We will see how you can score models on a variety of data sources.
- Use a functional methodology, i.e., we will create functions to automate the modeling, validation, and scoring process.

## Prerequisites

- Understanding of `rxDataStep` and `xdfs`
- Familiarity with `RevoScaleR` modeling and datastep functions: `rxLinMod`, `rxGlm`, `rxLogit`, `rxDTree`, `rxDForest`, `rxSplit`, and `rxPredict`
- Understand how to write functions in R
- Access to at least one interesting dataset

## Typical Lifecycle

<img src="images/revo-split-life-cycle.png" width="893" height="279px" />

Typical Modeling Lifecycle:

- Start with a data set
- Split into a training set and validation set(s)
- Use the `ScaleR` modeling functions on the train set to estimate your model
- Use `rxPredict` to validate/score your results

## Datasets | Mortgage Dataset

- We will work with mortgage dataset, which contains mortgage and credit profiles for various mortgage holders

```{r create_path_to_mortgages}
mort_path <- paste(rxGetOption("sampleDataDir"),
                   "mortDefaultSmall.xdf", 
                   sep = "/")
file.copy(mort_path, "mortgage.xdf", overwrite = TRUE)
mort_xdf <- RxXdfData("mortgage.xdf")
rxGetInfo(mort_xdf, getVarInfo = TRUE)
```

## Datasets | Convert Default to Categorical

- We might be interested in estimating a classification model for predicting defaults based on credit attributes

```{r add_default_flag}
rxDataStep(inData = mort_xdf,
           outFile = mort_xdf,
           overwrite = TRUE, 
           transforms = list(default_flag = factor(ifelse(default == 1,
                                                          "default",
                                                          "current"))
                             )
           )

```


# Modeling
## Generating Training and Test Sets | Create Partition

- The first step to estimating a model is having a clean training dataset.
- We will work with the mortgage data and use `rxSplit` to create partitions.
- `rxSplit` splits an input `.xdf` into multiple `.xdfs`, similar in spirit to the `split` function in base R
- output is a list
- First step is to create a split variable
- We will randomly partition the data into a train and test sample, with 75% in the former, and 25% in the latter

## Generating Training and Test Sets | Partition Function

```{r partition_function}


create_partition <- function(xdf = mort_xdf,
                             partition_size = 0.75,
                             output_path = "/output/", ...) {
  rxDataStep(inData = xdf,
             outFile = xdf,
             transforms = list(
               trainvalidate = factor(
                   ifelse(rbinom(.rxNumRows, 
                                 size = 1, prob = splitperc), 
                          "train", "validate")
               )
           ),
           transformObjects = list(splitperc = partition_size),
           overwrite = TRUE, ...)
  
  splitDS <- rxSplit(inData = xdf, 
                     outFilesBase = "",
                     outFileSuffixes = c("train", "validate"),
                     splitByFactor = "trainvalidate",
                     overwrite = TRUE)
  
  return(splitDS) 
  
}

```

## Generating Training and Test Sets | List of xdfs

- The `create_partition` function will output a list `xdfs`

```{r split_mortgages_data}
mort_split <- create_partition()
names(mort_split) <- c("train", "validate")
lapply(mort_split, rxGetInfo)

```


## Build Your Model | Model Formula

- Once you have your training dataset, the most appropriate next step is to estimate your model
- `ScaleR` provides a plethora of modeling functions to choose from: decision trees, ensemble trees, linear models, and generalized linear models.

```{r model_function}
make_form <- function(xdf = mort_xdf,
                      resp_var = "default_flag",
                      vars_to_skip = c("default", "trainvalidate")) {
  
  library(stringr)
  
  non_incl <- paste(vars_to_skip, collapse = "|")
  
  x_names <- names(xdf)
  
  features <- x_names[!str_detect(x_names, resp_var)]
  features <- features[!str_detect(features, non_incl)]
  
  form <- as.formula(paste(resp_var, paste0(features, collapse = " + "),
                           sep  = " ~ "))
  
  return(form)
}


```

## Build Your Model | Modeling Function

- Use the `make_form` function inside your favorite `rx` modeling function

```{r train_function}

make_form()

estimate_model <- function(xdf_data = mort_split[["train"]],
                           form = make_form(xdf_data),
                           model = rxLogit, ...) {
  
  rx_model <- model(form, data = xdf_data)
  
  return(rx_model)
  
  
}

```

## Build Your Model | Estimate Your Model

- Let us now train our model using the `estimate_model` function from the last slide

```{r train_models, message = FALSE}
default_model_logit <- estimate_model(mort_split$train, 
                                      reportProgress = 0)

```


## Building Additional Models | Reusing our Function

- We can change the parameters of the `estimate_model` function to create a different model relatively quickly

```{rr train_tree}
default_model_tree <- estimate_model(mort_split$train, 
                                     model = rxDTree, 
                                     cp = 0, type = 'class')

```


# Validation
## How Does it Perform on Unseen Data | rxPredict for Logistic Regression

```{r remove_any_older_xdf, echo = FALSE, message = F}
if(file.exists("scored.xdf")) file.remove('scored.xdf')
```

- Now that we have built our model, our next step is to see how it performs on data it has yet to see
- We can use the `rxPredict` function to score/validate our results

```{r test_logistic_model}

default_logit_scored <- rxPredict(default_model_logit,
                                   mort_split$validate,
                                   "scored.xdf",
                                  writeModelVars = TRUE)

```


## Get Receiver Operator Characteristics

- We can visualize our test results
```{r default_factor}
rxGetInfo(default_logit_scored, numRows = 2)
rxDataStep(inData = default_logit_scored, 
           outFile = default_logit_scored,
           transforms = list(default_binary = ifelse(default_flag == "default",
                                                     1, 
                                                     0)),
           overwrite = TRUE)
```

## Visualize Model Results

```{r roc_curve}
rxRocCurve("default_binary", "default_flag_Pred", data = default_logit_scored)

```


## Testing a Second Model | rxPredict for Decision Tree

- We saw how easy it was to train on different in the previous sections
- Similary simple to test different models

```{r test_d_tree_model}
default_tree_scored <- rxPredict(default_model_tree,
                                  mort_split$validate,
                                  "scored.xdf",
                                  writeModelVars = TRUE)

```

## Visualize Multiple ROCs

```{r roc_multiple}
rxRocCurve("default_binary", 
           c("default_flag_Pred", "default_prob"), 
           data = default_tree_scored)

```


# More Advanced Topics

## Scoring on Non-XDF Data Sources | Using CSV

- The previous slides focused on using xdf data sources
- Most of the `rx` functions will work on non-xdf data sources
- For training, which is often an iterative process, it is recommended to use xdfs
- For scoring/testing, which requires just one pass through the data, feel free to use raw data!

```{r csv_copy}

csv_path <- paste(rxGetOption("sampleDataDir"),
                   "mortDefaultSmall2009.csv", 
                   sep = "/")
file.copy(csv_path, "mortDefaultSmall2009.csv", overwrite = TRUE)

mort_csv <- RxTextData("mortDefaultSmall2009.csv")

```

## Regression Tree

- For a slightly different model, we will estimate a regression tree.
- Just change the parameters in the `estimate_model` function

```{r reg_tree}
tree_model_ccdebt <- estimate_model(xdf_data = mort_split$train, 
                                    form = make_form(mort_split$train, 
                                                     "ccDebt", 
                                                     vars_to_skip = c("default_flag",
                                                                      "trainvalidate")), 
                                    model = rxDTree)
# plot(RevoTreeView::createTreeView(tree_model_ccdebt))


```


## Test on CSV

```{r, echo = FALSE, message = FALSE, warnings = FALSE}
if (file.exists("mort2009predictions.xdf")) file.remove("mort2009predictions.xdf")
```


```{r test_csv}

rxPredict(tree_model_ccdebt, 
          data = mort_csv, 
          outData = "mort2009predictions.xdf", 
          writeModelVars = TRUE)

mort_2009_pred <- RxXdfData("mort2009predictions.xdf")
rxGetInfo(mort_2009_pred, numRows = 1)


```

# Multiclass Classification
## Convert Year to Factor

- We have seen how to estimate a binary classification model and a regression tree
- How would we estimate a multiclass classification model?
- Let's try to predict mortgage origination based on other variables
- Use `rxFactors` to convert *year* to a _factor_ variable

```{r create_year_factor}

mort_xdf_factor <- rxFactors(inData = mort_xdf, 
                             factorInfo = c("year"), 
                             outFile = "mort_year.xdf", 
                             overwrite = TRUE)


```

## Convert Year to Factor
```{r view_multiclass}
rxGetInfo(mort_xdf_factor, getVarInfo = TRUE)


```

## Estimate Multiclass Classification

- You know the drill! Change the parameters in `estimate_model`:

```{r multiclass_tree}
tree_multiclass_year <- estimate_model(xdf_data = mort_xdf_factor, 
                                    form = make_form(mort_xdf_factor, 
                                                     "year", 
                                                     vars_to_skip = c("default", 
                                                                      "trainvalidate")), 
                                    model = rxDTree, type = "class")


```

## Predict Multiclass Classification

- Score the results

```{r multiclass_prediction}

multiclass_preds <- rxPredict(tree_multiclass_year, 
                              data = mort_xdf_factor, 
                              writeModelVars = TRUE, 
                              outData = "multi.xdf",
                              overwrite = TRUE)

```

## Predict Multiclass Classification

- View the results
- Predicted/scored column for each level of the response
- Sum up to one
```{r multiclass_view}

rxGetInfo(multiclass_preds, numRows = 1)

```


# Conclusion

## Thanks for Attending!

- Any questions?
- Try different models!
- Try modeling with `rxDForest`, `rxBTrees`: have significantly higher predictive accuracy, somewhat less interpretability
- [alizaidi@microsoft.com](mailto:alizaidi@microsoft.com)